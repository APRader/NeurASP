{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Reliable Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Reliable Path (MRP) is a variant of the Shortest Path Problem, where, each edge is\n",
    "randomly associated with probabilities (0.512 or 0.8) which denotes the “reliability” of the edge,\n",
    "and the task is to find the most reliable path between the source and the destination node. We\n",
    "do not remove edges this time.\n",
    "\n",
    "We use the same 5-layer MLP in the SP experiment as the baseline. We also use the simplepath and the reachability constraints to train the neural network by NeurASP. Besides, we\n",
    "use weak constraints to represent the probability of each edge in the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "In dataGen.py, a class named \"GridProbData\" is defined in the following way.\n",
    "\n",
    "GridProbData class has 6 attributes: train_data, test_data, valid_data, train_labels, test_labels, valid_labels.\n",
    "\n",
    "train_data is an numpy array of size (1800, 40). It consists of 1800 data as follows \n",
    "\n",
    "        [  \n",
    "          data,  \n",
    "          ...,  \n",
    "          data  \n",
    "        ]  \n",
    "\n",
    "where data is a vector (numpy array) of length 40. For example, the data shown below  \n",
    "\n",
    "        [  \n",
    "          0.512 0.8 0.512 0.8 0.512  \n",
    "          0.512 0.8 0.512 0.512 0.8  \n",
    "          0.8 0.512 0.512 0.8 0.512  \n",
    "          0.512 0.512 0.512 0.512 0.8  \n",
    "          0.512 0.8 0.512 0.8  \n",
    "          10000 00000 01000 0  \n",
    "        ]  \n",
    "\n",
    "defines the 24 probabilities of the 24 edges and specified that the nodes 0 and 11 are the starting and ending nodes.  \n",
    "train_labels is an numpy array of size (1800, 24). It consists of 1800 label as follows.  \n",
    "\n",
    "        [  \n",
    "          label,  \n",
    "          ...,  \n",
    "          label  \n",
    "        ]  \n",
    "\n",
    "where label is a vector (numpy array) of length 24. For example, the label shown below  \n",
    "\n",
    "        [11100 00000 00000 00000 0110]  \n",
    "\n",
    "means that the edges 0, 1, 2, 21, 22 form a most reliable path.  \n",
    "test_data is a numpy array of size (600, 40).  \n",
    "valid_data is a numpy array of size (600, 40).  \n",
    "test_labels is a numpy array of size (600, 24).  \n",
    "valid_labels is a numpy array of size (600, 24).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataGen import GridProbData\n",
    "from neurasp import NeurASP\n",
    "from network import FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurASP Programs for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram = '''\n",
    "nn(sp(24, g), [true, false]).\n",
    "\n",
    "sp(X) :- sp(g,X,true).\n",
    "\n",
    "sp(0,1) :- sp(0).\n",
    "sp(1,2) :- sp(1).\n",
    "sp(2,3) :- sp(2).\n",
    "sp(4,5) :- sp(3).\n",
    "sp(5,6) :- sp(4).\n",
    "sp(6,7) :- sp(5).\n",
    "sp(8,9) :- sp(6).\n",
    "sp(9,10) :- sp(7).\n",
    "sp(10,11) :- sp(8).\n",
    "sp(12,13) :- sp(9).\n",
    "sp(13,14) :- sp(10).\n",
    "sp(14,15) :- sp(11).\n",
    "sp(0,4) :- sp(12).\n",
    "sp(4,8) :- sp(13).\n",
    "sp(8,12) :- sp(14).\n",
    "sp(1,5) :- sp(15).\n",
    "sp(5,9) :- sp(16).\n",
    "sp(9,13) :- sp(17).\n",
    "sp(2,6) :- sp(18).\n",
    "sp(6,10) :- sp(19).\n",
    "sp(10,14) :- sp(20).\n",
    "sp(3,7) :- sp(21).\n",
    "sp(7,11) :- sp(22).\n",
    "sp(11,15) :- sp(23).\n",
    "\n",
    "sp(X,Y) :- sp(Y,X).\n",
    "\n",
    ":- X=0..15, #count{Y: sp(X,Y)} = 1.\n",
    ":- X=0..15, #count{Y: sp(X,Y)} >= 3.\n",
    "reachable(X, Y) :- sp(X, Y).\n",
    "reachable(X, Y) :- reachable(X, Z), sp(Z, Y).\n",
    ":- sp(X, _), sp(Y, _), not reachable(X, Y).\n",
    "'''\n",
    "\n",
    "dprogram_test = '''\n",
    "sp(X) :- sp(g,X,true).\n",
    "\n",
    "sp(0,1) :- sp(0).\n",
    "sp(1,2) :- sp(1).\n",
    "sp(2,3) :- sp(2).\n",
    "sp(4,5) :- sp(3).\n",
    "sp(5,6) :- sp(4).\n",
    "sp(6,7) :- sp(5).\n",
    "sp(8,9) :- sp(6).\n",
    "sp(9,10) :- sp(7).\n",
    "sp(10,11) :- sp(8).\n",
    "sp(12,13) :- sp(9).\n",
    "sp(13,14) :- sp(10).\n",
    "sp(14,15) :- sp(11).\n",
    "sp(0,4) :- sp(12).\n",
    "sp(4,8) :- sp(13).\n",
    "sp(8,12) :- sp(14).\n",
    "sp(1,5) :- sp(15).\n",
    "sp(5,9) :- sp(16).\n",
    "sp(9,13) :- sp(17).\n",
    "sp(2,6) :- sp(18).\n",
    "sp(6,10) :- sp(19).\n",
    "sp(10,14) :- sp(20).\n",
    "sp(3,7) :- sp(21).\n",
    "sp(7,11) :- sp(22).\n",
    "sp(11,15) :- sp(23).\n",
    "\n",
    "sp(X,Y) :- sp(Y,X).\n",
    "\n",
    ":- X=0..15, #count{Y: sp(X,Y)} = 1.\n",
    ":- X=0..15, #count{Y: sp(X,Y)} >= 3.\n",
    "reachable(X, Y) :- sp(X, Y).\n",
    "reachable(X, Y) :- reachable(X, Z), sp(Z, Y).\n",
    ":- sp(X, _), sp(Y, _), not reachable(X, Y).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Define nnMapping: a dictionary that maps neural network names (i.e., strings) to the neural network objects (i.e., torch.nn.Module object)\n",
    "- Define optimizers: a dictionary that specifies the optimizer for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = FC(40, 50, 50, 50, 50, 50, 24)\n",
    "\n",
    "nnMapping = {'sp': m}\n",
    "\n",
    "optimizer = {'sp':torch.optim.Adam(m.parameters(), lr=0.001)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NeurASP object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeurASPobj = NeurASP(dprogram, nnMapping, optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataList and obsList for Training, testDataList and testObsList for Testing\n",
    "### Create the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GridProbData(\"data/data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dataList and obsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "obsList = []\n",
    "\n",
    "for i, d in enumerate(dataset.train_data):\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    dataList.append({'g': d_tensor})\n",
    "\n",
    "with open('data/evidence_train.txt', 'r') as f:\n",
    "    obsList = f.read().strip().strip('#evidence').split('#evidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct testDataList and testObsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataListTest = []\n",
    "obsListTest = []\n",
    "\n",
    "for d in dataset.test_data:\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    dataListTest.append({'g': d_tensor})\n",
    "\n",
    "with open('data/evidence_test.txt', 'r') as f:\n",
    "    obsListTest = f.read().strip().strip('#evidence').split('#evidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Note that our target is to find the path with the highest probability, which is represented by the optimal stable models of the logic program. To find the optimal stable models instead of stable models during training, we need to specify \"opt=True\" in the learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "for i in range(20):\n",
    "    print('Continuously training for 10 epochs round {}...'.format(i+1))\n",
    "    time1 = time.time()\n",
    "    NeurASPobj.learn(dataList=dataList, obsList=obsList, epoch=10, opt=True, smPickle='data/stableModels.pickle')\n",
    "    time2 = time.time()\n",
    "    NeurASPobj.testConstraint(dataList=dataListTest, obsList=obsListTest, mvppList=[dprogram_test])\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))\n",
    "    print('--- total time from beginning: %s minutes ---' % int((time.time() - startTime)/60) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
