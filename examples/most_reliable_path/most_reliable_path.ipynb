{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Reliable Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Reliable Path (MRP) is a variant of the Shortest Path Problem, where, each edge is\n",
    "randomly associated with probabilities (0.512 or 0.8) which denotes the “reliability” of the edge,\n",
    "and the task is to find the most reliable path between the source and the destination node. We\n",
    "do not remove edges this time.\n",
    "\n",
    "We use the same 5-layer MLP in the SP experiment as the baseline. We also use the simplepath and the reachability constraints to train the neural network by NeurASP. Besides, we\n",
    "use weak constraints to represent the probability of each edge in the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "In dataGen.py, a class named \"GridProbData\" is defined in the following way.\n",
    "\n",
    "GridProbData class has 6 attributes: train_data, test_data, valid_data, train_labels, test_labels, valid_labels.\n",
    "\n",
    "train_data is an numpy array of size (1800, 40). It consists of 1800 data as follows \n",
    "\n",
    "        [  \n",
    "          data,  \n",
    "          ...,  \n",
    "          data  \n",
    "        ]  \n",
    "\n",
    "where data is a vector (numpy array) of length 40. For example, the data shown below  \n",
    "\n",
    "        [  \n",
    "          0.512 0.8 0.512 0.8 0.512  \n",
    "          0.512 0.8 0.512 0.512 0.8  \n",
    "          0.8 0.512 0.512 0.8 0.512  \n",
    "          0.512 0.512 0.512 0.512 0.8  \n",
    "          0.512 0.8 0.512 0.8  \n",
    "          10000 00000 01000 0  \n",
    "        ]  \n",
    "\n",
    "defines the 24 probabilities of the 24 edges and specified that the nodes 0 and 11 are the starting and ending nodes.  \n",
    "train_labels is an numpy array of size (1800, 24). It consists of 1800 label as follows.  \n",
    "\n",
    "        [  \n",
    "          label,  \n",
    "          ...,  \n",
    "          label  \n",
    "        ]  \n",
    "\n",
    "where label is a vector (numpy array) of length 24. For example, the label shown below  \n",
    "\n",
    "        [11100 00000 00000 00000 0110]  \n",
    "\n",
    "means that the edges 0, 1, 2, 21, 22 form a most reliable path.  \n",
    "test_data is a numpy array of size (600, 40).  \n",
    "valid_data is a numpy array of size (600, 40).  \n",
    "test_labels is a numpy array of size (600, 24).  \n",
    "valid_labels is a numpy array of size (600, 24).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataGen import GridProbData\n",
    "from neurasp import NeurASP\n",
    "from network import FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurASP Programs for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprogram = '''\n",
    "nn(sp(24, g), [true, false]).\n",
    "\n",
    "sp(X) :- sp(g,X,true).\n",
    "\n",
    "sp(0,1) :- sp(0).\n",
    "sp(1,2) :- sp(1).\n",
    "sp(2,3) :- sp(2).\n",
    "sp(4,5) :- sp(3).\n",
    "sp(5,6) :- sp(4).\n",
    "sp(6,7) :- sp(5).\n",
    "sp(8,9) :- sp(6).\n",
    "sp(9,10) :- sp(7).\n",
    "sp(10,11) :- sp(8).\n",
    "sp(12,13) :- sp(9).\n",
    "sp(13,14) :- sp(10).\n",
    "sp(14,15) :- sp(11).\n",
    "sp(0,4) :- sp(12).\n",
    "sp(4,8) :- sp(13).\n",
    "sp(8,12) :- sp(14).\n",
    "sp(1,5) :- sp(15).\n",
    "sp(5,9) :- sp(16).\n",
    "sp(9,13) :- sp(17).\n",
    "sp(2,6) :- sp(18).\n",
    "sp(6,10) :- sp(19).\n",
    "sp(10,14) :- sp(20).\n",
    "sp(3,7) :- sp(21).\n",
    "sp(7,11) :- sp(22).\n",
    "sp(11,15) :- sp(23).\n",
    "\n",
    "sp(X,Y) :- sp(Y,X).\n",
    "\n",
    ":- X=0..15, #count{Y: sp(X,Y)} = 1.\n",
    ":- X=0..15, #count{Y: sp(X,Y)} >= 3.\n",
    "reachable(X, Y) :- sp(X, Y).\n",
    "reachable(X, Y) :- reachable(X, Z), sp(Z, Y).\n",
    ":- sp(X, _), sp(Y, _), not reachable(X, Y).\n",
    "'''\n",
    "\n",
    "dprogram_test = '''\n",
    "sp(X) :- sp(g,X,true).\n",
    "\n",
    "sp(0,1) :- sp(0).\n",
    "sp(1,2) :- sp(1).\n",
    "sp(2,3) :- sp(2).\n",
    "sp(4,5) :- sp(3).\n",
    "sp(5,6) :- sp(4).\n",
    "sp(6,7) :- sp(5).\n",
    "sp(8,9) :- sp(6).\n",
    "sp(9,10) :- sp(7).\n",
    "sp(10,11) :- sp(8).\n",
    "sp(12,13) :- sp(9).\n",
    "sp(13,14) :- sp(10).\n",
    "sp(14,15) :- sp(11).\n",
    "sp(0,4) :- sp(12).\n",
    "sp(4,8) :- sp(13).\n",
    "sp(8,12) :- sp(14).\n",
    "sp(1,5) :- sp(15).\n",
    "sp(5,9) :- sp(16).\n",
    "sp(9,13) :- sp(17).\n",
    "sp(2,6) :- sp(18).\n",
    "sp(6,10) :- sp(19).\n",
    "sp(10,14) :- sp(20).\n",
    "sp(3,7) :- sp(21).\n",
    "sp(7,11) :- sp(22).\n",
    "sp(11,15) :- sp(23).\n",
    "\n",
    "sp(X,Y) :- sp(Y,X).\n",
    "\n",
    ":- X=0..15, #count{Y: sp(X,Y)} = 1.\n",
    ":- X=0..15, #count{Y: sp(X,Y)} >= 3.\n",
    "reachable(X, Y) :- sp(X, Y).\n",
    "reachable(X, Y) :- reachable(X, Z), sp(Z, Y).\n",
    ":- sp(X, _), sp(Y, _), not reachable(X, Y).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Define nnMapping: a dictionary that maps neural network names (i.e., strings) to the neural network objects (i.e., torch.nn.Module object)\n",
    "- Define optimizers: a dictionary that specifies the optimizer for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Structure: (40, 50, 50, 50, 50, 50, 24)\n"
     ]
    }
   ],
   "source": [
    "m = FC(40, 50, 50, 50, 50, 50, 24)\n",
    "\n",
    "nnMapping = {'sp': m}\n",
    "\n",
    "optimizer = {'sp':torch.optim.Adam(m.parameters(), lr=0.001)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NeurASP object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeurASPobj = NeurASP(dprogram, nnMapping, optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataList and obsList for Training, testDataList and testObsList for Testing\n",
    "### Create the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3000 data in total, 60% training data, 20% validation data, 20% testing data!\n"
     ]
    }
   ],
   "source": [
    "dataset = GridProbData(\"data/data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dataList and obsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "obsList = []\n",
    "\n",
    "for i, d in enumerate(dataset.train_data):\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    dataList.append({'g': d_tensor})\n",
    "\n",
    "with open('data/evidence_train.txt', 'r') as f:\n",
    "    obsList = f.read().strip().strip('#evidence').split('#evidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct testDataList and testObsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataListTest = []\n",
    "obsListTest = []\n",
    "\n",
    "for d in dataset.test_data:\n",
    "    d_tensor = Variable(torch.from_numpy(d).float(), requires_grad=False)\n",
    "    dataListTest.append({'g': d_tensor})\n",
    "\n",
    "with open('data/evidence_test.txt', 'r') as f:\n",
    "    obsListTest = f.read().strip().strip('#evidence').split('#evidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Note that our target is to find the path with the highest probability, which is represented by the optimal stable models of the logic program. To find the optimal stable models instead of stable models during training, we need to specify \"opt=True\" in the learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuously training for 10 epochs round 1...\n",
      "The accuracy for constraint 1 is 0.0\n",
      "--- train time: 57.582571029663086 seconds ---\n",
      "--- test time: 5.7079596519470215 seconds ---\n",
      "--- total time from beginning: 1 minutes ---\n",
      "Continuously training for 10 epochs round 2...\n",
      "The accuracy for constraint 1 is 0.0\n",
      "--- train time: 58.763999938964844 seconds ---\n",
      "--- test time: 5.77888822555542 seconds ---\n",
      "--- total time from beginning: 2 minutes ---\n",
      "Continuously training for 10 epochs round 3...\n",
      "The accuracy for constraint 1 is 0.0\n",
      "--- train time: 58.62405037879944 seconds ---\n",
      "--- test time: 5.654390573501587 seconds ---\n",
      "--- total time from beginning: 3 minutes ---\n",
      "Continuously training for 10 epochs round 4...\n",
      "The accuracy for constraint 1 is 0.0\n",
      "--- train time: 57.486855268478394 seconds ---\n",
      "--- test time: 5.713911771774292 seconds ---\n",
      "--- total time from beginning: 4 minutes ---\n",
      "Continuously training for 10 epochs round 5...\n",
      "The accuracy for constraint 1 is 0.0\n",
      "--- train time: 84.83867859840393 seconds ---\n",
      "--- test time: 5.662351131439209 seconds ---\n",
      "--- total time from beginning: 5 minutes ---\n",
      "Continuously training for 10 epochs round 6...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a0ad726cd849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Continuously training for 10 epochs round {}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtime1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mNeurASPobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobsList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobsList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmPickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/stableModels.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtime2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mNeurASPobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataListTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobsList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobsListTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmvppList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdprogram_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\NeurASP\\neurasp.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, dataList, obsList, epoch, alpha, lossFunc, method, lr, opt, storeSM, smPickle, accEpoch, batchSize)\u001b[0m\n\u001b[0;32m    345\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnnOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                                 \u001b[0mnnOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnGradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnnOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                                 \u001b[0mnnOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnGradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnnOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "for i in range(20):\n",
    "    print('Continuously training for 10 epochs round {}...'.format(i+1))\n",
    "    time1 = time.time()\n",
    "    NeurASPobj.learn(dataList=dataList, obsList=obsList, epoch=10, opt=True, smPickle='data/stableModels.pickle')\n",
    "    time2 = time.time()\n",
    "    NeurASPobj.testConstraint(dataList=dataListTest, obsList=obsListTest, mvppList=[dprogram_test])\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))\n",
    "    print('--- total time from beginning: %s minutes ---' % int((time.time() - startTime)/60) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table compares the different accuracies on the test data between MLP Only\n",
    "trained by cross entropy loss and the same MLP trained by NeurASP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "path=\"accuracy_comparison.jpg\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above table, the label accuracy is the measure against the label for which the neural\n",
    "network is trained for. Note that the MRP problem (and the SP and the top K in the next\n",
    "section) are not “functional” problems in the sense that there may be multiple solutions\n",
    "possible. In such a case, we select only one among them as the label in the training set to be in\n",
    "favor of neural network learning.\n",
    "\n",
    "However, it is possible that the prediction different from the label is still correct. To account for\n",
    "this, we consider the ultimate accuracy, which counts such prediction correct. The near\n",
    "ultimate accuracy is similar but a bit more relaxed. It allows more predictions to be correct by\n",
    "including near optimal paths in which the number of edges is the same as that of a most\n",
    "reliable path but a 0.512 edge is contained instead of a 0.8 edge.\n",
    "\n",
    "The constraint accuracy counts if the prediction satisfies the simple-path and the reachability\n",
    "constraints regardless whether it’s most reliable or not.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
