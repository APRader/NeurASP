{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "path=\"4by4_grid.jpg\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 4*4 grid above.\n",
    "\n",
    "There are 16 nodes and 24 edges in the grid. Given any 2 nodes in the grid, the target is to find\n",
    "a shortest path between them. We use the dataset from (Xu et al. 2018), which was used to\n",
    "demonstrate the effectiveness of semantic constraints for enhanced neural network learning.\n",
    "Each example is a 4 by 4 grid G = (V,E), where |V | = 16,|E| = 24. The source and the destination\n",
    "nodes are randomly picked up, as well as 8 edges are randomly removed to increase the\n",
    "difficulty. The dataset is divided into 60/20/20 train/validation/test examples.\n",
    "\n",
    "We apply NeurASP on this problem using the same dataset and the neural network model\n",
    "from (Xu et al. 2018), but with a different training target: to maximize the probability of the\n",
    "training data under the semantics of NeurASP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "In dataGen.py, a dictionary named \"dataset\" is constructed in the following way.\n",
    "\n",
    "dataset is a dictionary with 6 keys: train, test, valid, train_label, test_label, valid_label.\n",
    "\n",
    "dataset[‘train’] is a numpy array of size (966, 40). It consists of 966 data as follows.  \n",
    "\n",
    "    [  \n",
    "      data,  \n",
    "      ...,  \n",
    "      data  \n",
    "    ]  \n",
    "    \n",
    "where data is a vector (numpy array) of length 40. For example, the data shown below  \n",
    "\n",
    "    [  \n",
    "      11101 10111 10001 11110 1010  \n",
    "      01000 00000 00010 0  \n",
    "    ]  \n",
    "\n",
    "means the edges 3, 6, 11, 12, 13, 19, 21, 23 are removed (denoted by 0 in the 1st line); and the nodes 1 and 13 are the starting and ending nodes (denoted by 1 in the 2nd line).\n",
    "\n",
    "dataset[‘train_label’] is a numpy array of size (996, 24). It consists of 966 label as  \n",
    "follows.  \n",
    "\n",
    "    [  \n",
    "      label,  \n",
    "      ...,  \n",
    "      label  \n",
    "    ]  \n",
    "\n",
    "where label is a vector (numpy array) of length 24. For example, the label shown below \n",
    "\n",
    "    [  \n",
    "      00000 00000 00000 11100 0000  \n",
    "    ]  \n",
    "\n",
    "means that the edges 15, 16, 17 form a shortest path.  \n",
    "dataset[‘test’] is a numpy array of size (322, 40).  \n",
    "dataset[‘valid’] is a numpy array of size (322, 40).  \n",
    "dataset[‘test_label’] is a numpy array of size (322, 24).  \n",
    "dataset[‘valid_label’] is a numpy array of size (322, 24).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from neurasp import NeurASP\n",
    "from network import FC\n",
    "from dataGen import obsList, obsListTest, dataList, dataListTest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurASP program\n",
    "### Neural Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnRule = '''\n",
    "nn(sp(24, g), [true, false]).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASP Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspRule = '''\n",
    "sp(X) :- sp(g,X,true).\n",
    "\n",
    "sp(0,1) :- sp(0).\n",
    "sp(1,2) :- sp(1).\n",
    "sp(2,3) :- sp(2).\n",
    "sp(4,5) :- sp(3).\n",
    "sp(5,6) :- sp(4).\n",
    "sp(6,7) :- sp(5).\n",
    "sp(8,9) :- sp(6).\n",
    "sp(9,10) :- sp(7).\n",
    "sp(10,11) :- sp(8).\n",
    "sp(12,13) :- sp(9).\n",
    "sp(13,14) :- sp(10).\n",
    "sp(14,15) :- sp(11).\n",
    "sp(0,4) :- sp(12).\n",
    "sp(4,8) :- sp(13).\n",
    "sp(8,12) :- sp(14).\n",
    "sp(1,5) :- sp(15).\n",
    "sp(5,9) :- sp(16).\n",
    "sp(9,13) :- sp(17).\n",
    "sp(2,6) :- sp(18).\n",
    "sp(6,10) :- sp(19).\n",
    "sp(10,14) :- sp(20).\n",
    "sp(3,7) :- sp(21).\n",
    "sp(7,11) :- sp(22).\n",
    "sp(11,15) :- sp(23).\n",
    "\n",
    "sp(X,Y) :- sp(Y,X).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_con = '''\n",
    "% [nr] 1. No removed edges should be predicted\n",
    "mistake :- sp(X), removed(X).\n",
    "'''\n",
    "\n",
    "path_con = '''\n",
    "% [p] 2. Prediction must form simple path(s)\n",
    "% that is: the degree of nodes should be either 0 or 2\n",
    "mistake :- X=0..15, #count{Y: sp(X,Y)} = 1.\n",
    "mistake :- X=0..15, #count{Y: sp(X,Y)} >= 3.\n",
    "'''\n",
    "\n",
    "reach_con = '''\n",
    "% [r] 3. Every 2 nodes in the prediction must be reachable\n",
    "reachable(X, Y) :- sp(X, Y).\n",
    "reachable(X, Y) :- reachable(X, Z), sp(Z, Y).\n",
    "mistake :- sp(X, _), sp(Y, _), not reachable(X, Y).\n",
    "'''\n",
    "\n",
    "opt_con = '''\n",
    "% [o] 4. Predicted path should contain least edges\n",
    ":~ sp(X). [1, X]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Define nnMapping: a dictionary that maps neural network names (i.e., strings) to the neural network objects (i.e., torch.nn.Module object)\n",
    "- Define optimizers: a dictionary that specifies the optimizer for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = FC(40, 50, 50, 50, 50, 50, 24)\n",
    "nnMapping = {'sp': m}\n",
    "optimizers = {'sp': torch.optim.Adam(m.parameters(), lr=0.001)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NeurASP Object\n",
    "\n",
    "We use all constraints to train the neural network, which corresponds to the experiment nr-p-r-opt at the table at the end of this document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeurASPobj = NeurASP(nnRule+aspRule+path_con+reach_con+opt_con, nnMapping, optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mvppList to Test Constraint Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvppList = [remove_con, path_con, reach_con, remove_con+path_con, remove_con+reach_con, path_con+reach_con, remove_con+path_con+reach_con, remove_con+path_con+reach_con+opt_con]\n",
    "mvppList = [aspRule+i for i in mvppList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------------')\n",
    "for idx, constraint in enumerate(mvppList):\n",
    "    print('Constraint {} is\\n{}\\n-------------------'.format(idx+1, constraint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Note that our target is to find the path with the minimal length, which is represented by the optimal stable models of the logic program. To find the optimal stable models instead of stable models during training, we need to specify \"opt=True\" in the learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Start training and testing\n",
    "########\n",
    "mvppList = [remove_con, path_con, reach_con, remove_con+path_con, remove_con+reach_con, path_con+reach_con, remove_con+path_con+reach_con, remove_con+path_con+reach_con+opt_con]\n",
    "mvppList = [aspRule+i for i in mvppList]\n",
    "\n",
    "for idx, constraint in enumerate(mvppList):\n",
    "    print('Constraint {} is\\n{}\\n-------------------'.format(idx+1, constraint))\n",
    "\n",
    "startTime = time.time()\n",
    "for i in range(50):\n",
    "    print('Continuously training for 10 epochs round {}...'.format(i+1))\n",
    "    time1 = time.time()\n",
    "    NeurASPobj.learn(dataList=dataList, obsList=obsList, epoch=10, opt=True, smPickle='data/stableModels.pickle')\n",
    "    time2 = time.time()\n",
    "    NeurASPobj.testConstraint(dataList=dataListTest, obsList=obsListTest, mvppList=mvppList)\n",
    "    print(\"--- train time: %s seconds ---\" % (time2 - time1))\n",
    "    print(\"--- test time: %s seconds ---\" % (time.time() - time2))\n",
    "    print('--- total time from beginning: %s minutes ---' % int((time.time() - startTime)/60) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More results: The following table shows the constraint accuracy of the same MLP trained with\n",
    "different constraints (denoted in the parentheses) for 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"constraint_accuracies.jpg\"\n",
    "display(Image.open(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
